{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "el7RmXPfm1TC",
        "outputId": "d73bf856-77be-4243-933a-23e8a1355e28"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "import random\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk import word_tokenize\n",
        "from nltk import ConditionalFreqDist\n",
        "from nltk.probability import ConditionalProbDist, MLEProbDist\n",
        "import codecs\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "nltk.download('punkt')\n",
        "!pip3 install konlpy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "rlbWFuPy4iZQ",
        "outputId": "88d20450-cfc1-4fee-8f3d-3cc0cf857f6e"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()\n",
        "comments_log = list(uploaded.keys())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXPqxsCgwe72",
        "outputId": "c115b213-7b69-4d9a-dacb-d73e61529221"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "텍스트 데이터: ['\"t1행동\"', '\"세최미\"', '\"어이 페이커 이걸로 \"동률\"이다\"', '\"연륜\"', '\"일보후퇴 이보전진\"']\n",
            "\n",
            "문장 개수:  9250\n"
          ]
        }
      ],
      "source": [
        "with codecs.open(comments_log, encoding = 'utf-8') as f:\n",
        "  reader = csv.reader(f, delimiter='\\t')   # Read and process data\n",
        "  data = list(reader)[1:]\n",
        "\n",
        "comment = [row[0] for row in data]   # Extract documents\n",
        "print(\"텍스트 데이터:\", comment[:5])\n",
        "print(\"\\n문장 개수: \", len(comment))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Ud3MeWGNwe5e"
      },
      "outputs": [],
      "source": [
        "tagger = Okt()\n",
        "\n",
        "def tokenize(text):\n",
        "\n",
        "  tokens = ['/'.join(t) for t in tagger.pos(text)]   # Tokenize text using KoNLPy\n",
        "\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHvHDwRRwe_f",
        "outputId": "81e24855-ad4b-4a5e-f296-f1f8cb3e6aca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9251/9251 [00:08<00:00, 1120.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('', '\\ufeff/Foreign'), ('\\ufeff/Foreign', 'Comments/Alpha'), ('Comments/Alpha', ''), ('', '\"/Punctuation'), ('\"/Punctuation', 't/Alpha'), ('t/Alpha', '1/Number'), ('1/Number', '행동/Noun'), ('행동/Noun', '\"/Punctuation'), ('\"/Punctuation', ''), ('', '\"/Punctuation')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "sentences = []\n",
        "\n",
        "# Create bigrams from tekenized sentences\n",
        "for d in tqdm(comment):\n",
        "  tokens = tokenize(d)\n",
        "  bigram = ngrams(tokens, 2, pad_left = True, pad_right = True, left_pad_symbol = \"\", right_pad_symbol = \"\")\n",
        "  sentences += [t for t in bigram]\n",
        "\n",
        "\n",
        "print(sentences[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G1tOKe99T3u",
        "outputId": "2459a4c6-a289-4ef8-bf6d-63a0e3701c09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('대/Verb', 614), ('와/Verb', 308), ('대상/Noun', 234), ('티원/Noun', 178), ('제/Modifier', 147)]\n"
          ]
        }
      ],
      "source": [
        "# Create Conditional Frequency Distribution\n",
        "cfd = ConditionalFreqDist(sentences)\n",
        "print(cfd[\"\"].most_common(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYvdmB_4yDVD",
        "outputId": "388fbe06-607b-4bbf-854d-92a649c6a55d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('상/Noun', 498), ('황/Noun', 77), ('우/Adverb', 16), ('0/Number', 11), ('마/Noun', 9), ('떡/Noun', 5), ('오/Noun', 4), ('표/Noun', 4), ('1/Number', 3), ('-/Punctuation', 3)]\n"
          ]
        }
      ],
      "source": [
        "# Function to find most common words following a given token\n",
        "def most_common(c, n, pos = None):\n",
        "\n",
        "  if pos is None:\n",
        "    return cfd[tokenize(c)[0]].most_common(n)\n",
        "  else:\n",
        "    return cfd[\"/\".join([c, pos])].most_common(n)\n",
        "\n",
        "\n",
        "print(most_common(\"대\", 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY2yvKEGyDX0",
        "outputId": "2f0bde54-eef3-46ce-db06-e20f23105347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.2191780821917808\n"
          ]
        }
      ],
      "source": [
        "# Create Conditional Probability Distribution based on word frequencies\n",
        "cpd = ConditionalProbDist(cfd, MLEProbDist)\n",
        "print(cpd[tokenize(\".\")[0]].prob(\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE5YH0HWyFeT",
        "outputId": "157a115b-1ac1-4032-cb9e-f318e91dd357"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.7410714285714286\n",
            "0.0\n"
          ]
        }
      ],
      "source": [
        "# Probability of a word w following a context c in bigram\n",
        "def bigram_prob(c, w):\n",
        "\n",
        "  context = tokenize(c)[0]\n",
        "  word = tokenize(w)[0]\n",
        "\n",
        "  return cpd[context].prob(word)\n",
        "\n",
        "\n",
        "print(bigram_prob(\"대\", \"상\"))\n",
        "print(bigram_prob(\"상\", \"대\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Gmdd-MuTyFgp"
      },
      "outputs": [],
      "source": [
        "# Generate a sentence based on the learned probabilities\n",
        "def generate_sentence(seed = None):\n",
        "\n",
        "  if seed is not None:\n",
        "    random.seed(seed)\n",
        "  c = \"\"\n",
        "  sentence = []\n",
        "\n",
        "  while True:\n",
        "    if c not in cpd:\n",
        "      break\n",
        "\n",
        "    w = cpd[c].generate()\n",
        "\n",
        "    if w == \"\":\n",
        "      break\n",
        "\n",
        "    word = w.split(\"/\")[0]\n",
        "    pos = w.split(\"/\")[1]\n",
        "\n",
        "    # Add words to the sentence based on certain conditions\n",
        "    if c == \"\":\n",
        "      sentence.append(word.title())\n",
        "    elif c in [\"`\", \"\\\"\",\"'\",\"(\"]:\n",
        "      sentence.append(word)\n",
        "    elif word in [\"'\", \".\", \",\", \")\", \":\", \";\", \"?\"]:\n",
        "      sentence.append(word)\n",
        "    elif pos in [\"Josa\", \"Punctuation\", \"Suffix\"]:\n",
        "        sentence.append(word)\n",
        "    elif w in [\"임/Noun\", \"것/Noun\", \"는걸/Noun\", \"릴때/Noun\",\n",
        "                \"되다/Verb\", \"이다/Verb\", \"하다/Verb\", \"이다/Adjective\"]:\n",
        "        sentence.append(word)\n",
        "    else:\n",
        "        sentence.append(\" \" + word)\n",
        "    c = w\n",
        "\n",
        "  return \"\".join(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykkAEL_RyJHq",
        "outputId": "54ec7193-90a5-4779-cbd3-4a4f855f52eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "구마 유시가 막히게 현상금 붙네\n",
            "표 시기 잘 해 ㅋㅋㅋㅋㅋㅋ\n",
            "대 상 혁\n",
            "대 황 식\n",
            "오우 너 ㅋㅋㅋㅋ 그냥 미쳤네 ㅋㅋㅋㅋㅋㅋㅋ\n",
            "주도권 나갔다\n",
            "도사 ㄷㄷ\n",
            "대 포 고 듀가 만만한가\n",
            "발차기 실패\n",
            "압승인데 ㅋㅋㅋㅋㅋㅋㅋ\n"
          ]
        }
      ],
      "source": [
        "# Print sentences\n",
        "for i in range(1, 11):\n",
        "    print(generate_sentence(i))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
